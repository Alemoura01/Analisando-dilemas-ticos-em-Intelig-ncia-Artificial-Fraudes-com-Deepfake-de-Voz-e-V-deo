# ğŸ­ AnÃ¡lise CrÃ­tica de um Dilema Ã‰tico em IA  
## Caso: Fraudes com Deepfake de Voz e VÃ­deo

Este repositÃ³rio contÃ©m uma anÃ¡lise crÃ­tica sobre o uso inadequado da **InteligÃªncia Artificial** para a criaÃ§Ã£o de **deepfakes** (Ã¡udio e vÃ­deo), com foco em como essa tecnologia tem sido usada em **fraudes financeiras, manipulaÃ§Ã£o polÃ­tica e desinformaÃ§Ã£o**.

ğŸ“„ Acesse o documento completo em PDF:  
ğŸ‘‰ [Deepfake_Fraudes_IA.pdf](Deepfake_Fraudes_IA.pdf)

---

## ğŸ” Resumo do Caso
Em 2019, criminosos usaram IA de clonagem de voz para enganar o CEO de uma empresa de energia no Reino Unido, que acreditou estar falando com o chefe da matriz. O executivo autorizou a transferÃªncia de **US$ 243.000** para uma conta fraudulenta. Desde entÃ£o, casos semelhantes vÃªm crescendo, atingindo empresas e cidadÃ£os comuns.

---

## ğŸ“š Framework Aplicado
- **NIST AI Risk Management Framework (AI RMF 1.0)**: governar, mapear riscos, medir e mitigar.  
- **ACM Code of Ethics & UNESCO**: evitar danos, proteger direitos humanos, combater desinformaÃ§Ã£o.

---

## âš–ï¸ Principais Pontos da AnÃ¡lise
- **GovernanÃ§a**: falta de regras claras sobre quem pode usar sistemas de clonagem de voz/vÃ­deo.  
- **Riscos**: fraude bancÃ¡ria, manipulaÃ§Ã£o polÃ­tica, pornografia de vinganÃ§a, perda de confianÃ§a social.  
- **MitigaÃ§Ã£o**: watermarking digital, detectores de deepfake, regulaÃ§Ã£o legal, educaÃ§Ã£o digital.  
- **Ã‰tica**: uso fraudulento de IA viola princÃ­pios de justiÃ§a, seguranÃ§a e direitos humanos.

---

## ğŸ§‘â€ğŸ’» PosiÃ§Ã£o Profissional
O uso de IA generativa nÃ£o Ã© antiÃ©tico por si sÃ³, mas **sem controles tÃ©cnicos, jurÃ­dicos e sociais, os riscos superam os benefÃ­cios**.  
Ã‰ necessÃ¡ria **responsabilidade compartilhada** entre desenvolvedores, empresas, governos e sociedade.

---

## âœ… RecomendaÃ§Ãµes
- **Desenvolvedores**: restriÃ§Ãµes de uso, marcas digitais (*watermarking*), termos claros.  
- **Empresas**: detectores automÃ¡ticos e auditorias de seguranÃ§a.  
- **Governos**: legislar contra fraudes com IA.  
- **Sociedade**: alfabetizaÃ§Ã£o midiÃ¡tica e ciberseguranÃ§a bÃ¡sica.

---

## ğŸ“‚ Estrutura do RepositÃ³rio
- `Deepfake_Fraudes_IA.pdf` â†’ Documento completo em PDF  
- `README.md` â†’ Este arquivo de apresentaÃ§Ã£o

---

âœï¸ Criado para fins acadÃªmicos no curso de **AnÃ¡lise e Desenvolvimento de Sistemas (ADS)**.
